{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd057174",
   "metadata": {},
   "source": [
    "# code to extract information such as the number of pages, number of books on each page, total number of books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f7bb1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages: 50\n",
      "Number of books on each page: 20\n",
      "Total number of books: 1000\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Make a GET request to the first page of the website\n",
    "url = \"https://books.toscrape.com/catalogue/page-1.html\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the total number of pages\n",
    "num_pages = int(soup.find(\"li\", {\"class\": \"current\"}).text.strip().split()[-1])\n",
    "\n",
    "# Find the number of books on each page\n",
    "num_books_per_page = len(soup.find_all(\"article\", {\"class\": \"product_pod\"}))\n",
    "\n",
    "# Find the total number of books\n",
    "total_num_books = (num_pages - 1) * 20 + num_books_per_page\n",
    "\n",
    "# Print the results\n",
    "print(\"Number of pages:\", num_pages)\n",
    "print(\"Number of books on each page:\", num_books_per_page)\n",
    "print(\"Total number of books:\", total_num_books)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500fbb8b",
   "metadata": {},
   "source": [
    "# The number of books in each category. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "320b2834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Travel: 11 books\n",
      "Mystery: 20 books\n",
      "Historical Fiction: 20 books\n",
      "Sequential Art: 20 books\n",
      "Classics: 19 books\n",
      "Philosophy: 11 books\n",
      "Romance: 20 books\n",
      "Womens Fiction: 17 books\n",
      "Fiction: 20 books\n",
      "Childrens: 20 books\n",
      "Religion: 7 books\n",
      "Nonfiction: 20 books\n",
      "Music: 13 books\n",
      "Default: 20 books\n",
      "Science Fiction: 16 books\n",
      "Sports and Games: 5 books\n",
      "Add a comment: 20 books\n",
      "Fantasy: 20 books\n",
      "New Adult: 6 books\n",
      "Young Adult: 20 books\n",
      "Science: 14 books\n",
      "Poetry: 19 books\n",
      "Paranormal: 1 books\n",
      "Art: 8 books\n",
      "Psychology: 7 books\n",
      "Autobiography: 9 books\n",
      "Parenting: 1 books\n",
      "Adult Fiction: 1 books\n",
      "Humor: 10 books\n",
      "Horror: 17 books\n",
      "History: 18 books\n",
      "Food and Drink: 20 books\n",
      "Christian Fiction: 6 books\n",
      "Business: 12 books\n",
      "Biography: 5 books\n",
      "Thriller: 11 books\n",
      "Contemporary: 3 books\n",
      "Spirituality: 6 books\n",
      "Academic: 1 books\n",
      "Self Help: 5 books\n",
      "Historical: 2 books\n",
      "Christian: 3 books\n",
      "Suspense: 1 books\n",
      "Short Stories: 1 books\n",
      "Novels: 1 books\n",
      "Health: 4 books\n",
      "Politics: 3 books\n",
      "Cultural: 1 books\n",
      "Erotica: 1 books\n",
      "Crime: 1 books\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Make a GET request to the website\n",
    "url = \"https://books.toscrape.com/\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the link to the \"Books\" category\n",
    "books_category = soup.select('a[href*=\"/category/books_1/\"]')\n",
    "\n",
    "# Find all the subcategories within the \"Books\" category\n",
    "subcategories = books_category[0].find_next(\"ul\").find_all(\"a\")\n",
    "\n",
    "# Loop through each subcategory\n",
    "for subcategory in subcategories:\n",
    "    category_url = url + subcategory['href']\n",
    "    category_response = requests.get(category_url)\n",
    "    category_soup = BeautifulSoup(category_response.content, \"html.parser\")\n",
    "    num_books = len(category_soup.select('article.product_pod'))\n",
    "    print(f\"{subcategory.text.strip()}: {num_books} books\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe848fc",
   "metadata": {},
   "source": [
    "## The data is saved in a CSV file for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65267856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Make a GET request to the website\n",
    "url = \"https://books.toscrape.com/\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the link to the \"Books\" category\n",
    "books_category = soup.select('a[href*=\"/category/books_1/\"]')\n",
    "\n",
    "# Find all the subcategories within the \"Books\" category\n",
    "subcategories = books_category[0].find_next(\"ul\").find_all(\"a\")\n",
    "\n",
    "# Create a list to store the category and number of books\n",
    "data = []\n",
    "\n",
    "# Loop through each subcategory and get the number of books\n",
    "for subcategory in subcategories:\n",
    "    subcategory_url = url + subcategory['href']\n",
    "    subcategory_response = requests.get(subcategory_url)\n",
    "    subcategory_soup = BeautifulSoup(subcategory_response.content, \"html.parser\")\n",
    "    num_books = len(subcategory_soup.select(\"article.product_pod\"))\n",
    "    data.append({\"Category\": subcategory.text.strip(), \"Num Books\": num_books})\n",
    "\n",
    "# Save the data to a CSV file\n",
    "with open(\"data/categories_data.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=[\"Category\", \"Num Books\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
